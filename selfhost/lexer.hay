include "std.hay"
include "file.hay"
include "stack.hay"
include "arr.hay"

include "selfhost/ir/token.hay"
include "selfhost/ir/function.hay"
include "selfhost/ir/op.hay"
include "selfhost/ir/types/type.hay"
include "selfhost/ir/types/type_names.hay"

struct &str {
    u64: foo
}

var u8[65536]: filebuff_p
var Token[65536]: token_buff_p
var Stack<Token>: tokens_p

var Str[512]: included_files_p
var Stack<Str>: include_files_stack

var *Type[16384]: misc_types_buffer_p
var Stack<*Type>: misc_types_stack_p

fn IncludeFiles.add(Str: file_name) {
    file_name include_files_stack Stack.push drop
}

fn IncludeFiles.contains(Str: file_name) -> [bool] {
    
    include_files_stack @ as [stk]

    false 0 while as [continue i] { continue i
        continue lnot
        i stk::size < land
    }
    {
        as [_ i]
        i stk::arr Arr.get file_name Str.equals
        i 1 +
    } drop
} 

fn expect_token_keyword(Token: prev_tok Keyword: kw) -> [Token] {
    tokens_p Stack.pop as [maybe_tok]

    maybe_tok Opt.is_some if {
        maybe_tok Opt.unwrap as [next]
        
        next::kind::tag TokenKindTag::Keyword ==
        next::kind::value::keyword kw         == land
        lnot if {
            prev_tok::loc Loc.puts
            ": Expected " puts kw Keyword.puts ", but found " puts next::kind::value::keyword Keyword.puts " instead" putlns
            "    Note: Tag: " puts next::kind::tag TokenKindTag::Keyword == putlnb
            1 exit    
        }
        next
    } else {
        prev_tok::loc Loc.puts
        ": Expected " puts kw Keyword.puts ", but found no token instead" putlns
        1 exit
        TokenKind.from_eof "" 0 0 cast(Loc) cast(Token)
    }
}

fn peek_token_kind(TokenKind: kind) -> [bool] {

    tokens_p Stack.peek as [maybe_tok]

    maybe_tok Opt.is_some if {
        maybe_tok Opt.unwrap as [tok]
        tok::kind kind TokenKind.equals 
    } else {
        false
    }

}

fn expect_token_kind(Token: prev_tok TokenKind: kind) -> [Token] {
    tokens_p Stack.pop as [maybe_tok]
    maybe_tok Opt.is_some if {
        maybe_tok Opt.unwrap as [next]
        next::kind kind TokenKind.equals lnot if {
            prev_tok Token.puts
            ": Expected a " puts kind TokenKind.puts 
            ", but found " puts next::kind TokenKind.puts
            "instead" putlns
            1 exit
        }
        next
    } else {
        "Expected a word, but found no token instead" putlns
        1 exit
        TokenKind.from_eof "" 0 0 cast(Loc) cast(Token)
    }
}

fn expect_word(Token: prev_tok) -> [Token Str] {
    tokens_p Stack.pop as [maybe_tok]
    maybe_tok Opt.is_some if {
        maybe_tok Opt.unwrap as [next]
        next::kind::tag TokenKindTag::Word == lnot if {
            prev_tok Token.puts
            ": Expected a word, but found " puts next::kind TokenKind.puts
            "instead" putlns
            1 exit
        }
        next next::kind::value::word
    } else {
        "Expected a word, but found no token instead" putlns
        1 exit
        TokenKind.from_eof "" 0 0 cast(Loc) cast(Token) ""
    }
}

fn expect_string_literal(Token: prev_tok) -> [Token Str] {
    tokens_p Stack.pop as [maybe_tok] 
    maybe_tok Opt.is_some if {

        maybe_tok Opt.unwrap as [next]

        next::kind::tag TokenKindTag::Literal ==
        next::kind::value::literal::tag LiteralTag::Str == land
        lnot if {
            "Expected a string literal, but found " puts next::kind TokenKind.puts
            "instead" putlns
            1 exit
        }

        next next::kind::value::literal::value::Str

    } else {
        "Expected a string literal, but found no token instead" putlns
        1 exit
        TokenKind.from_eof "" 0 0 cast(Loc) cast(Token) ""
    }
}

fn push_token(Token) {
    tokens_p Stack.push Opt.is_some if {
        "Tokens Stack overflow!" putlns
        1 exit
    }
}

fn parse_comment(*Loc: loc Str: s) -> [Str] {

    s while as [str] { str
        "\n" str Str.starts_with lnot 
        str::size 0 >            land 
    }
    {
        as [str] 
        str::size 1 - 
        str::data 1 ptr+
        cast(Str)

        1 loc loc_bump
    }

}

fn Str.is_numeric(Str: s) -> [bool] {

    true 0 while dup s::size < {
        as [cond i]
        s::data i ptr+ @ cast(u64) as [char]
        48 char <= char 57 <= land
        cond land
        i 1 +  
    } drop
}

fn Str.to_u64(Str: s) -> [u64] {

    s Str.is_numeric lnot if {
        "Cannot convert non numeric string `" puts
        s puts
        "` to a u64" putlns
        1 exit
    }

    s::size s::data cast(Arr) as [arr]

    0 0 while dup s::size < {
        as [result idx]
        result 10 * 
        idx arr Arr.get cast(u64) 48 - +
        idx 1 +
    } drop

}

fn parse_word(*Loc: loc Str: s) -> [Str] {
    0 s::data cast(Str)
    s while as [str] { str                       // Break on:
        " "  str Str.starts_with       lnot      //  * space
        "\n" str Str.starts_with       lnot land //  * newline
        str Marker.try_from_str Opt.is_none land //  * marker
        str::data @ cast(u64) 34 !=         land //  * quote
        str::size 0 >                       land //  * empty string
    }
    {
        as [word str]
        word::size 1 + word::data       cast(Str)
        str::size  1 - str::data 1 ptr+ cast(Str)
    }
    as [word str]
    word Str.is_numeric if {
        word Str.to_u64 Literal.from_u64 TokenKind.from_literal loc @ cast(Token)
    } else word Keyword.try_from_str Opt.is_some if {
        word Keyword.try_from_str Opt.unwrap 
        TokenKind.from_keyword loc @ cast(Token)
    } else word Operator.try_from_str Opt.is_some if {
        word Operator.try_from_str Opt.unwrap
        TokenKind.from_operator loc @ cast(Token)
    } else {
        word TokenKind.from_word loc @ cast(Token)
    }

    push_token
    word::size loc loc_bump
    str

}

fn parse_string_literal(*Loc: loc Str: s) -> [Str] {
    
    s::data @ cast(u64) 34 != if {
        "Parsing string failed. Expected double quote, but found: `" puts 
        0 1 s Str.substr puts
        "` instead." putlns
        1 exit
    }

    1 s::data cast(Str)
    s::size 1 - s::data 1 ptr+ cast(Str)
    while as [str] { str
        str::data @ cast(u64) 34 !=
        str::size 0 >               land
    }
    {
        as [word str]
        0 1 str Str.substr as [char]
        word::size 1 + word::data       cast(Str)
        str::size  1 - str::data 1 ptr+ cast(Str)
    }

    as [word str] {
        str::data @ cast(u64) 34 != if {
            "Didn't find end of string" putlns
            1 exit
        }
        word::size 1 + word::data       cast(Str)
        str::size  1 - str::data 1 ptr+ cast(Str)
    }
    
    as [word str]
    
    word::size 2 - word::data 1 ptr+ cast(Str)
    Literal.from_str TokenKind.from_literal loc @ cast(Token)
    push_token

    0 while dup word::size < {
        as [i]
        i 1 word Str.substr "\n" Str.equals if {
            loc loc_newline
        } else {
            1 loc loc_bump
        }
        i 1 +
    } drop

    str

}

fn loc_bump(u64: n *Loc: loc_p) {
    loc_p @ as [loc]
    loc::file loc::row loc::col n + cast(Loc)
    loc_p !
}

fn loc_newline(*Loc: loc_p) {
    loc_p @ as [loc]
    loc::file loc::row 1 + 1 cast(Loc)
    loc_p !
}

fn parse_next(*Loc: loc Str: str) -> [Str] {
    str::size 0 == if {
        "No token to be found..." putlns
        str
    } else {
        " " str Str.starts_with if {
            1 loc loc_bump
            1 str::size 1 - str Str.substr
        } else "\n" str Str.starts_with if {
            loc loc_newline
            1 str::size 1 - str Str.substr
        } else "//" str Str.starts_with if {
            loc str parse_comment
        } else str Marker.try_from_str Opt.is_some if {
            str Marker.try_from_str Opt.unwrap as [marker]
            marker TokenKind.from_marker loc @ cast(Token) push_token
            marker Marker.to_str as [marker_str] 
            marker_str::size loc loc_bump
            marker_str::size str::size marker_str::size - str Str.substr
        } else str::data @ cast(u64) 34 == if {
            loc str parse_string_literal
        } else {
            loc str parse_word
        }
    }
    
    
}

fn parse_tokens(Str: path Str: input) {
    var Loc: loc
    var Str: token

    tokens_p @ as [stk] {
        stk::size 
    } as [token_start]

    path 1 1 cast(Loc) loc !
    0 input::data cast(Str) token !

    input while as [str] { str
        str::size 0 >
    }
    {
        as [str]
        loc str parse_next
    } drop

    TokenKind.from_eof loc @ cast(Token) push_token
    tokens_p @ as [stk] {
        stk::size token_start -
        stk::arr::data token_start ptr+ 
        cast(Arr)
        Arr.rev
    }
}

fn parse_type(Token: start_tok) -> [Token *Type Opt<u64>] {
    Operator::Mul TokenKind.from_operator peek_token_kind if {

        start_tok Operator::Mul TokenKind.from_operator expect_token_kind as [ptr_tok]
        ptr_tok parse_type as [tok type arrany_n]
        type_names.start
            "*" type_names.push_str
            type type_names.push_existing
        type_names.finish
        TypeKind::Pointer TypeBuilder.start
            type TypeBulider.set.pointer.from_type
            TypeBuilder.finish
        type_map_p Map.get_ref Opt.unwrap as [ptr_type]

        tok ptr_type arrany_n
    } else {
        
        start_tok expect_word as [name_tok name]
        name_tok parse_annotation_list as [tok maybe_annotations]

        name type_map_p Map.get_ref as [maybe_type]

        maybe_type Opt.is_some if {

            tok maybe_type Opt.unwrap Opt.None::<u64>

        } else {

            name TypeKind::Placeholder TypeBuilder.start
                TypeBuilder.finish
            type_map_p Map.get_ref Opt.unwrap as [placeholder_type]
            tok placeholder_type Opt.None::<u64>

        }

    }

}

fn parse_untagged_type(Token: start_tok) -> [Opt<Token> Opt<*Type> Opt<u64>] {

    ""            TokenKind.from_word     peek_token_kind
    Operator::Mul TokenKind.from_operator peek_token_kind lor if {

        start_tok parse_type as [tok type arr_n]

        tok Opt.Some type Opt.Some arr_n
        
    } else {
        Opt.None::<Token> Opt.None::<*Type> Opt.None::<u64>
    }

}

fn parse_annotation_list(Token: start_tok) -> [Token Opt<Arr<*Type>>] {

    Operator::LessThan TokenKind.from_operator peek_token_kind if {

        start_tok Operator::LessThan TokenKind.from_operator expect_token_kind as [open_tok]
        misc_types_stack_p @ as [misc_types] {
            misc_types::arr::data misc_types::size ptr+
        } as [annotations_start]

        0 open_tok while dup parse_untagged_type as [maybe_tok maybe_type arr_n] {
            maybe_tok maybe_type arr_n
            maybe_type Opt.is_some
        }
        {
            as [n prev_tok maybe_tok maybe_type arr_n]
            maybe_tok Opt.unwrap maybe_type Opt.unwrap as [tok type]
            
            arr_n Opt.is_some if {
                tok::loc Loc.puts
                ": Cannot have array values in annotation list." putlns
                1 exit
            }

            type misc_types_stack_p Stack.push Opt.is_some if {
                "Misc Type stack ran out of room. Consider adding more memory" putlns
                1 exit
            }

            n 1 + tok
        } drop drop drop as [n tok]

        tok n annotations_start cast(Arr) Opt.Some



    } else {
        start_tok Opt.None::<Arr<*Type>>
    }

}

fn parse_signature(Token: start_tok) -> [Token Signature ] {

    Marker::OpenParen TokenKind.from_marker expect_token_kind as [open_paren_tok]
 


}

fn parse_function(Token: start_tok) -> [Function] {

    start_tok Keyword::Function expect_token_keyword as [fn_tok]
    fn_tok expect_word as [name_tok name]
    "Parsing Function: `" puts name puts "`" putlns
    name_tok parse_annotation_list as [ann_token maybe_generics]

    maybe_generics Opt.is_some if {
        maybe_generics Opt.unwrap as [annotations]
        "  Found an annotation list:" putlns
        "    * [" puts
        0 while dup annotations::size < {
            as [n]

            n 0 != if {
                " " puts
            }

            n annotations Arr.get type_map_p Map.reverse_lookup puts
            n 1 +
        } drop
    } else {
        "  No annotation list provided" putlns 
    }

    ann_token parse_signature

    "Parsing Functions isn't completed yet." putlns
    1 exit    

    ""
    start_tok
    0 0 cast(**Type) cast(Arr)
    0 0 cast(**Type) cast(Arr)
    cast(Signature)
    0 0 cast(*Op) cast(Arr)
    cast(Function)

}

fn hay_into_ir(Str: input_path) {

    var u64[128]: path_buff
    0 path_buff @ memset

    "Hay into IR: " puts input_path putlns

    input_path filebuff_p @ File.read_path_to_str as [file_str]
    input_path file_str parse_tokens

    while tokens_p Stack.peek Opt.unwrap as [tok] { tok
        tok::kind::tag TokenKindTag::EndOfFile == lnot 
    } {
        as [tok]

        "Parsing Token: " puts tok Token.puts "\n" puts

        tok::kind::tag TokenKindTag::Keyword == if {
            tok::kind::value::keyword as [kw]
            
            kw Keyword::Function == if {
                
                tok parse_function drop

            } else kw Keyword::Include == if {
                
                tok Keyword::Include expect_token_keyword
                expect_string_literal as [path] {
                    
                    path IncludeFiles.contains lnot if {
                        path IncludeFiles.add

                        path File.exists if {
                            path
                        } else {
                            0 path_buff @ memset
                            "./src/libs/" path path_buff @ split cast(u64) cast(*u8) cast(Arr) Str.concat
                            as [src_str]
                            src_str File.exists if {
                                src_str
                            } else {
                                path
                                "Compiler Error: Could not import file `" puts path puts "`." putlns
                                1 exit 
                            }
                        }
                        Opt.Some
                    } else {
                        Opt.None::<Str>
                    }
                }
                as [token maybe_path]

                maybe_path Opt.is_some if {
                    maybe_path Opt.unwrap as [path]
                    path hay_into_ir
                } 
            } else kw Keyword::Struct == if {
                "Todo: Parse struct types: " puts
                tok Token.puts "\n" puts
                1 exit
            } else kw Keyword::Union == if {
                "Todo: Parse union types: " puts
                tok Token.puts "\n" puts
                1 exit
            } else kw Keyword::Enum == if {
                "Todo: Parse enum types: " puts
                tok Token.puts "\n" puts
                1 exit
            } else kw Keyword::Var == if {
                "Todo: Parse variables: " puts
                tok Token.puts "\n" puts
                1 exit
            } else {
                "Unexpected keyword: " puts tok Token.puts "\n" puts
                1 exit
            }
            
        } else {
            "Unexpected token: " puts tok Token.puts "\n" puts
            1 exit
        }

    } drop

}

fn main() {
    included_files_p @ include_files_stack Stack.init
    token_buff_p @ tokens_p  Stack.init

    type_list.init
    type_names.init 

    "./selfhost/lexer.hay" hay_into_ir
}