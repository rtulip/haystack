include "std.hay"
include "file.hay"
include "stack.hay"

include "selfhost/ir/token.hay"

var u8[65536]: filebuff_p
var Token[65536]: token_buff_p
var Stack<Token>: tokens_p

var Str[512]: included_files_p
var Stack<Str>: include_files_stack

fn IncludeFiles.add(Str: file_name) {
    file_name include_files_stack Stack.push drop
}

fn IncludeFiles.contains(Str: file_name) -> [bool] {
    
    include_files_stack @ as [stk]

    false 0 while as [continue i] { continue i
        continue lnot
        i stk::size < land
    }
    {
        as [_ i]
        i stk::arr Arr.get file_name Str.equals
        i 1 +
    } drop
} 

fn expect_token_keyword(Token: prev_tok Keyword: kw) -> [Token] {
    tokens_p Stack.pop as [maybe_tok]

    maybe_tok Opt.is_some if {
        maybe_tok Opt.unwrap as [next]
        
        next::kind::tag TokenKindTag::Keyword ==
        next::kind::value::keyword kw         == land
        lnot if {
            prev_tok::loc Loc.puts
            ": Expected " puts kw Keyword.puts ", but found " puts next::kind::value::keyword Keyword.puts " instead" putlns
            "    Note: Tag: " puts next::kind::tag TokenKindTag::Keyword == putlnb
            1 exit    
        }
        next
    } else {
        prev_tok::loc Loc.puts
        ": Expected " puts kw Keyword.puts ", but found no token instead" putlns
        1 exit
        TokenKind.from_eof "" 0 0 cast(Loc) cast(Token)
    }
}

fn expect_string_literal(Token: prev_tok) -> [Token Str] {
    tokens_p Stack.pop as [maybe_tok] 
    maybe_tok Opt.is_some if {

        maybe_tok Opt.unwrap as [next]

        next::kind::tag TokenKindTag::Literal ==
        next::kind::value::literal::tag LiteralTag::Str == land
        lnot if {
            "Expected a string literal, but found " puts next::kind TokenKind.puts
            "instead" putlns
            1 exit
        }

        next next::kind::value::literal::value::Str

    } else {
        "Expected a string literal, but found no token instead" putlns
        1 exit
        TokenKind.from_eof "" 0 0 cast(Loc) cast(Token) ""
    }
}

fn push_token(Token) {
    tokens_p Stack.push Opt.is_some if {
        "Tokens Stack overflow!" putlns
        1 exit
    }
}

fn parse_comment(*Loc: loc Str: s) -> [Str] {

    s while as [str] { str
        "\n" str Str.starts_with lnot 
        str::size 0 >            land 
    }
    {
        as [str] 
        str::size 1 - 
        str::data 1 ptr+
        cast(Str)

        1 loc loc_bump
    }

}

fn Str.is_numeric(Str: s) -> [bool] {

    true 0 while dup s::size < {
        as [cond i]
        s::data i ptr+ @ cast(u64) as [char]
        48 char <= char 57 <= land
        cond land
        i 1 +  
    } drop
}

fn Str.to_u64(Str: s) -> [u64] {

    s Str.is_numeric lnot if {
        "Cannot convert non numeric string `" puts
        s puts
        "` to a u64" putlns
        1 exit
    }

    s::size s::data cast(Arr) as [arr]

    0 0 while dup s::size < {
        as [result idx]
        result 10 * 
        idx arr Arr.get cast(u64) 48 - +
        idx 1 +
    } drop

}

fn parse_word(*Loc: loc Str: s) -> [Str] {
    0 s::data cast(Str)
    s while as [str] { str                       // Break on:
        " "  str Str.starts_with       lnot      //  * space
        "\n" str Str.starts_with       lnot land //  * newline
        str Marker.try_from_str Opt.is_none land //  * marker
        str::data @ cast(u64) 34 !=         land //  * quote
        str::size 0 >                       land //  * empty string
    }
    {
        as [word str]
        word::size 1 + word::data       cast(Str)
        str::size  1 - str::data 1 ptr+ cast(Str)
    }
    as [word str]
    word Str.is_numeric if {
        word Str.to_u64 Literal.from_u64 TokenKind.from_literal loc @ cast(Token)
    } else word Keyword.try_from_str Opt.is_some if {
        word Keyword.try_from_str Opt.unwrap 
        TokenKind.from_keyword loc @ cast(Token)
    } else word Operator.try_from_str Opt.is_some if {
        word Operator.try_from_str Opt.unwrap
        TokenKind.from_operator loc @ cast(Token)
    } else {
        word TokenKind.from_word loc @ cast(Token)
    }

    push_token
    word::size loc loc_bump
    str

}

fn parse_string_literal(*Loc: loc Str: s) -> [Str] {
    
    s::data @ cast(u64) 34 != if {
        "Parsing string failed. Expected double quote, but found: `" puts 
        0 1 s Str.substr puts
        "` instead." putlns
        1 exit
    }

    1 s::data cast(Str)
    s::size 1 - s::data 1 ptr+ cast(Str)
    while as [str] { str
        str::data @ cast(u64) 34 !=
        str::size 0 >               land
    }
    {
        as [word str]
        0 1 str Str.substr as [char]
        word::size 1 + word::data       cast(Str)
        str::size  1 - str::data 1 ptr+ cast(Str)
    }

    as [word str] {
        str::data @ cast(u64) 34 != if {
            "Didn't find end of string" putlns
            1 exit
        }
        word::size 1 + word::data       cast(Str)
        str::size  1 - str::data 1 ptr+ cast(Str)
    }
    
    as [word str]
    
    word::size 2 - word::data 1 ptr+ cast(Str)
    Literal.from_str TokenKind.from_literal loc @ cast(Token)
    push_token

    0 while dup word::size < {
        as [i]
        i 1 word Str.substr "\n" Str.equals if {
            loc loc_newline
        } else {
            1 loc loc_bump
        }
        i 1 +
    } drop

    str

}

fn loc_bump(u64: n *Loc: loc_p) {
    loc_p @ as [loc]
    loc::file loc::row loc::col n + cast(Loc)
    loc_p !
}

fn loc_newline(*Loc: loc_p) {
    loc_p @ as [loc]
    loc::file loc::row 1 + 1 cast(Loc)
    loc_p !
}

fn parse_next(*Loc: loc Str: str) -> [Str] {
    str::size 0 == if {
        "No token to be found..." putlns
        str
    } else {
        " " str Str.starts_with if {
            1 loc loc_bump
            1 str::size 1 - str Str.substr
        } else "\n" str Str.starts_with if {
            loc loc_newline
            1 str::size 1 - str Str.substr
        } else "//" str Str.starts_with if {
            loc str parse_comment
        } else str Marker.try_from_str Opt.is_some if {
            str Marker.try_from_str Opt.unwrap as [marker]
            marker TokenKind.from_marker loc @ cast(Token) push_token
            marker Marker.to_str as [marker_str] 
            marker_str::size loc loc_bump
            marker_str::size str::size marker_str::size - str Str.substr
        } else str::data @ cast(u64) 34 == if {
            loc str parse_string_literal
        } else {
            loc str parse_word
        }
    }
    
    
}

fn parse_tokens(Str: path Str: input) {
    var Loc: loc
    var Str: token

    tokens_p @ as [stk] {
        stk::size 
    } as [token_start]

    path 1 1 cast(Loc) loc !
    0 input::data cast(Str) token !

    input while as [str] { str
        str::size 0 >
    }
    {
        as [str]
        loc str parse_next
    } drop

    TokenKind.from_eof loc @ cast(Token) push_token
    tokens_p @ as [stk] {
        stk::size token_start -
        stk::arr::data token_start ptr+ 
        cast(Arr)
        Arr.rev
    }
}

fn hay_into_ir(Str: input_path) {

    var u64[128]: path_buff
    0 path_buff @ memset


    input_path filebuff_p @ File.read_path_to_str as [file_str]
    input_path file_str parse_tokens

    while tokens_p Stack.peek Opt.unwrap as [tok] { tok
        tok::kind::tag TokenKindTag::EndOfFile == lnot 
    } {
        as [tok]

        "Parsing Token: " puts tok Token.puts "\n" puts

        tok::kind::tag TokenKindTag::Keyword == if {
            tok::kind::value::keyword as [kw]
            
            kw Keyword::Function == if {
                "Todo: Parse functions: " puts
                tok Token.puts "\n" puts
                1 exit
            } else kw Keyword::Include == if {
                
                tok Keyword::Include expect_token_keyword
                expect_string_literal as [path] {
                    
                    path IncludeFiles.contains lnot if {
                        path IncludeFiles.add

                        path File.exists if {
                            path
                        } else {
                            0 path_buff @ memset
                            "./src/libs/" path path_buff @ split cast(u64) cast(*u8) cast(Arr) Str.concat
                            as [src_str]
                            src_str File.exists if {
                                src_str
                            } else {
                                path
                                "Compiler Error: Could not import file `" puts path puts "`." putlns
                                1 exit 
                            }
                        }
                        Opt.Some
                    } else {
                        Opt.None::<Str>
                    }
                }
                as [token maybe_path]

                maybe_path Opt.is_some if {
                    maybe_path Opt.unwrap as [path]
                    path hay_into_ir
                } 
            } else kw Keyword::Struct == if {
                "Todo: Parse struct types: " puts
                tok Token.puts "\n" puts
                1 exit
            } else kw Keyword::Union == if {
                "Todo: Parse union types: " puts
                tok Token.puts "\n" puts
                1 exit
            } else kw Keyword::Enum == if {
                "Todo: Parse enum types: " puts
                tok Token.puts "\n" puts
                1 exit
            } else kw Keyword::Var == if {
                "Todo: Parse variables: " puts
                tok Token.puts "\n" puts
                1 exit
            } else {
                "Unexpected keyword: " puts tok Token.puts "\n" puts
                1 exit
            }
            
        } else {
            "Unexpected token: " puts tok Token.puts "\n" puts
            1 exit
        }

    } drop

}

fn main()
{

    included_files_p @ include_files_stack Stack.init
    token_buff_p @ tokens_p  Stack.init

    "./selfhost/lexer.hay" hay_into_ir

    //while tokens_p Stack.pop dup Opt.is_some {
    //    Opt.unwrap Token.puts "\n" puts
    //} drop
    
}