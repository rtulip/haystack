include "std.hay"
include "file.hay"
include "stack.hay"

include "selfhost/ir/program.hay"
include "selfhost/ir/tokens/token.hay"
include "selfhost/ir/tokens/tokenizer.hay"
include "selfhost/ir/types/type.hay"
include "selfhost/ir/function.hay"
include "selfhost/ir/op.hay"

fn peek_token_kind(*Stack<Token>: tokens TokenKind: kind) -> [bool] {
    
    tokens Stack.peek Opt.is_some if {
        tokens Stack.peek Opt.unwrap as [token]
        token::kind::tag kind::tag == if {

            token::kind::tag TokenKindTag::Keyword == if {
                token::kind::value::keyword kind::value::keyword ==
            } else token::kind::tag TokenKindTag::Operator == if {
                token::kind::value::operator kind::value::operator ==
            } else token::kind::tag TokenKindTag::Literal == if {
                token::kind::value::literal::tag kind::value::literal::tag == 
            } else token::kind::tag TokenKindTag::Marker == if {
                token::kind::value::marker kind::value::marker == 
            } else token::kind::tag TokenKindTag::Word == if {
                true
            } else token::kind::tag TokenKindTag::EndOfFile == if {
                true
            } else {
                "Unrecognized TokenKindTag" putlns
                1 exit 
                false
            }

        } else {
            false
        }
    } else {
        false
    }

}

fn expect_token_kind(Token: token *Stack<Token>: tokens TokenKind: kind) -> [Token] {

    tokens Stack.peek Opt.is_some if {

        tokens kind peek_token_kind if {

            tokens Stack.pop Opt.unwrap

        } else {
            "Expected " puts kind TokenKind.puts ", but found " puts tokens Stack.pop Opt.unwrap Token.puts " instead." putlns
            1 exit
            token 
        }
        
    } else {
        "Expected " puts kind TokenKind.puts ", but found empty tokens stack instead" putlns
        1 exit
        token
    }

    

}

fn expect_word(Token: prev_tok *Stack<Token>: tokens) -> [Token Str] {

    tokens Stack.pop as [maybe_tok]
    maybe_tok Opt.is_some if {

        maybe_tok Opt.unwrap as [tok]
        tok Token.word Opt.is_some if {

            tok tok Token.word Opt.unwrap

        } else {
            tok "" 
            tok::loc Loc.puts
            ": Expected a word, but found " puts tok Token.puts " instead." putlns
            1 exit
        }

    } else {
        prev_tok "" 
        prev_tok::loc Loc.puts
        ": Expected a word, but token stack was empty instead." putlns
        1 exit
    }

}

fn expect_u64(Token: prev_tok *Stack<Token>: tokens) -> [Token u64] {

    tokens Stack.pop as [maybe_tok]
    maybe_tok Opt.is_some if {

        maybe_tok Opt.unwrap as [tok]
        tok Token.literal Opt.is_some if {

            tok Token.literal Opt.unwrap as [lit]
            lit Literal.u64 Opt.is_some if {

                tok lit Literal.u64 Opt.unwrap 

            } else {
                tok 0
                tok::loc Loc.puts
                ": Expected a u64 literal, but found " puts tok Token.puts " instead." putlns
                1 exit
            }

        } else {
            tok 0 
            tok::loc Loc.puts
            ": Expected a u64 literal, but found " puts tok Token.puts " instead." putlns
            1 exit
        }

    } else {
        prev_tok 0 
        prev_tok::loc Loc.puts
        ": Expected a word, but token stack was empty instead." putlns
        1 exit
    }    

}

fn parse_maybe_tagged_type(
    Token: start_tok
    *Stack<Token>: tokens
    *Map<*Type>: types
) -> [Opt<Token> Opt<Str> Opt<*Type> Opt<u64>] {

    tokens Operator::Mul TokenKind.from_operator peek_token_kind
    tokens "" TokenKind.from_word peek_token_kind lor if {

        start_tok tokens types parse_type as [typ_tok typ dimension] 
        tokens Marker::Colon TokenKind.from_marker peek_token_kind if {
            typ_tok tokens Marker::Colon TokenKind.from_marker expect_token_kind
            tokens expect_word as [tok ident]

            tok   Opt.Some
            ident Opt.Some 
            typ   Opt.Some 
            dimension
        } else {
            typ_tok Opt.Some
                    Opt.None::<Str>
            typ     Opt.Some
            dimension
        }

    } else {
        Opt.None::<Token> Opt.None::<Str> Opt.None::<*Type> Opt.None::<u64>
    }

}

fn parse_maybe_tagged_type_list(
    Token: start_tok
    *Stack<Token>: tokens
    *Map<*Type>: types
) -> [*Stack<*Type> *Stack<Opt<Str>>] {

    Stack.new::<*Type> Stack.new::<Opt<Str>> as [inputs idents]
    start_tok while tokens types parse_maybe_tagged_type as [maybe_tok maybe_ident maybe_typ dimension]
    { maybe_tok maybe_ident maybe_typ dimension
        maybe_tok Opt.is_some
        maybe_typ Opt.is_some land
    }
    {
        as [maybe_tok maybe_ident maybe_typ dimension]
        
        maybe_tok Opt.unwrap maybe_typ Opt.unwrap as [tok typ]

        dimension Opt.is_some if {
            tok::loc Loc.puts
            ": Cannot have array types in type list" putlns
            1 exit
        }

        typ         inputs Stack.push
        maybe_ident idents Stack.push
        
        tok
    } drop drop drop drop

    inputs idents

}

fn parse_untagged_type_list(
    Token: start_tok
    *Stack<Token>: tokens
    *Map<*Type>: types
) -> [*Stack<*Type>] {

    Stack.new::<*Type> as [typs]
    start_tok while tokens types parse_untagged_type as [maybe_tok maybe_typ dimension]
    { maybe_tok maybe_typ dimension
        maybe_tok Opt.is_some
        maybe_typ Opt.is_some land
    }
    {
        as [maybe_tok maybe_typ dimension]
        maybe_tok Opt.unwrap maybe_typ Opt.unwrap as [tok typ]

        typ typs Stack.push

        tok

    } drop drop drop

    typs

}

fn parse_signature(
    Token: start_tok
    *Stack<Token>: tokens
    *Map<*Type>: types
) -> [Token Signature *Stack<Opt<Str>>]
{

    start_tok tokens Marker::OpenParen TokenKind.from_marker expect_token_kind as [inputs_start_tok]
    inputs_start_tok tokens types parse_maybe_tagged_type_list as [inputs idents]
    inputs_start_tok tokens Marker::CloseParen TokenKind.from_marker expect_token_kind as [inputs_close_tok]

    tokens Marker::Arrow TokenKind.from_marker peek_token_kind lnot if {
    
        inputs_close_tok inputs Stack.new::<*Type> cast(Signature) idents
    
    }  else {
        inputs_close_tok tokens Marker::Arrow TokenKind.from_marker expect_token_kind as [arrow_tok]
        arrow_tok tokens Marker::OpenBracket TokenKind.from_marker expect_token_kind as [output_start_tok]
        output_start_tok tokens types parse_untagged_type_list as [outputs]
        output_start_tok tokens Marker::CloseBracket TokenKind.from_marker expect_token_kind as [output_close_tok]
    
        output_close_tok inputs outputs cast(Signature) idents    
    }

}

fn parse_partial_type(
    Token: start_tok
    *Stack<Token>: tokens
    *Map<*Type>: types
) -> [Token *Type] {

    tokens Operator::Mul TokenKind.from_operator peek_token_kind if {

        start_tok tokens Operator::Mul TokenKind.from_operator expect_token_kind
        tokens types parse_partial_type as [typ_tok ptr_typ]

        ptr_typ Type.Pointer as [ptr] // leaked
        ptr Type.name as [ptr_name] // leaked

        ptr_name types Map.contains lnot if {
            ptr_name ptr types Map.insert drop
            ptr
        } else {
            ptr_name types Map.get Opt.unwrap
        }

        as [typ]
        
        typ_tok typ

    } else {

        start_tok tokens expect_word as [tok typ_name]
        typ_name types Map.get as [maybe_typ]

        maybe_typ Opt.is_some if {
            maybe_typ Opt.unwrap
        } else {

            typ_name Type.Placeholder as [t]
            typ_name t types Map.insert Opt.is_none lnot if {
                "This should be unreachable..." putlns
                1 exit
            }

            t
        } as [typ]

        tok typ
    }

}

fn parse_cast(
    Token: start_tok
    *Stack<Token>: tokens
    *Map<*Type>: types
) -> [Op] {

    start_tok tokens Marker::OpenParen TokenKind.from_marker expect_token_kind 
    tokens types parse_partial_type as [typ_tok typ]
    typ_tok tokens types parse_annotation_list as [ann_tok annotations]
    ann_tok tokens Marker::CloseParen TokenKind.from_marker expect_token_kind drop

    annotations Opt.is_some if {
        start_tok Op.Return
        
        "Assigning parsed annotations isn't implemented yet..." putlns
        1 exit
    } else {

        start_tok typ Op.Cast
    }

}

fn parse_size_of(
    Token: start_tok
    *Stack<Token>: tokens
    *Map<*Type>: types
) -> [Op] {

    start_tok tokens Marker::OpenParen TokenKind.from_marker expect_token_kind
    tokens types parse_type as [tok typ dimension]

    dimension Opt.is_some if {
        tok::loc Loc.puts
        ": Cannot have array values in sizeOf operator" putlns
        1 exit
    }

    tok tokens Marker::CloseParen TokenKind.from_marker expect_token_kind drop
    tok typ Op.SizeOf

}

fn make_ident_count(*Stack<Op>: ops_p u64: start_ip) -> [u64] {

    ops_p @ as [ops]

    0 start_ip while dup ops::len < {

        as [var_count ip]

        ip ops::slice Arr.get as [op]
        op::kind::tag OpKindTag::MakeIdent == if {
            var_count 1 + 
        } else op::kind::tag OpKindTag::EndBlock == if {
            var_count op::kind::value::EndBlock -
        } else {
            var_count
        }

        ip 1 +  

    } drop


}

fn parse_while_block(
    Token: token
    *Stack<Token>: tokens
    *Stack<Op>: ops
    *Map<*Type>: types
    // TODO: init_data
){

    token Keyword::While Op.Nop ops Stack.push
    ops @ as [ops_] { ops_::len } as [loop_dest]

    Stack.new::<TokenKind> as [break_on] {
        Marker::OpenBrace TokenKind.from_marker break_on Stack.push
        token tokens ops types break_on parse_tokens_until_tokenkind 
        break_on Stack.destroy
    } as [open_tok]
    
    ops @ as [ops_] { ops_::len } as [cond_jump_loc]
    open_tok Op.JumpCondNone ops Stack.push
    open_tok Op.StartBlock ops Stack.push

    Stack.new::<TokenKind> as [break_on] {
        Marker::CloseBrace TokenKind.from_marker break_on Stack.push
        token tokens ops types break_on parse_tokens_until_tokenkind 
        break_on Stack.destroy
    } as [close_tok]

    ops cond_jump_loc 1 + make_ident_count as [var_count]
    close_tok var_count Op.EndBlock ops Stack.push
    close_tok loop_dest Op.JumpSome ops Stack.push
    ops @ as [ops_] { ops_::len } as [end_loc]
    close_tok end_loc Op.JumpDest ops Stack.push
    
    ops @ as [ops_] { 
        cond_jump_loc ops_::slice Arr.get as [op]
        op::token end_loc Op.JumpCondSome 

        cond_jump_loc ops_::slice Arr.set
    }

}

fn parse_word_list(
    Token: start_tok
    *Stack<Token>: tokens
    TokenKind: open
    TokenKind: close
) -> [Token *Stack<Token> *Stack<Str>] {

    Stack.new::<Token> Stack.new::<Str> as [word_toks words]

    start_tok tokens open expect_token_kind
    while tokens "" TokenKind.from_word peek_token_kind {
        tokens expect_word as [word_tok word]
        word_tok word_toks Stack.push
        word     words     Stack.push
        word_tok 
    }

    tokens close expect_token_kind
    word_toks words

}

fn parse_as(
    Token: start_tok
    *Stack<Token>: tokens
    *Stack<Op>: ops
    *Map<*Type>: types
    // TODO: init data
) {

    start_tok 
    tokens 
    Marker::OpenBracket TokenKind.from_marker 
    Marker::CloseBracket TokenKind.from_marker
    parse_word_list as [list_end_tok word_toks_p words_p]
    word_toks_p @ words_p @ as [word_toks words]

    ops @ as [ops_] { ops_::len } as [start_idx]

    0 while dup words::len < {
        as [i]

        i word_toks::slice Arr.get
        i words::slice Arr.get
        Opt.None::<u64>
        Op.MakeIdent
        ops Stack.push

        i 1 +
    } drop

    tokens Marker::OpenBrace TokenKind.from_marker peek_token_kind if {

        list_end_tok tokens Marker::OpenBrace TokenKind.from_marker expect_token_kind as [tok]
        tok Op.StartBlock ops Stack.push

        Stack.new::<TokenKind> as [break_on] {
            Marker::CloseBrace TokenKind.from_marker break_on Stack.push
            tok tokens ops types break_on parse_tokens_until_tokenkind
            break_on Stack.destroy
        } as [close_tok]
    
        close_tok ops start_idx make_ident_count Op.EndBlock ops Stack.push    

    }

}

fn parse_tokens_until_tokenkind(
    Token: start_tok
    *Stack<Token>: tokens
    *Stack<Op>: ops
    *Map<*Type>: types
    // TODO: init data
    // TODO: locals
    *Stack<TokenKind>: break_on
) -> [Token] {

    var Opt<*Stack<*Type>>: annotations
    Opt.None::<*Stack<*Type>> annotations !

    false tokens Stack.pop while as [brk maybe_tok] { brk maybe_tok
        maybe_tok Opt.is_some brk lnot land
    }
    {

        

        as [brk maybe_tok]
        maybe_tok Opt.unwrap as [tok]

        break_on @ as [to_break]
        false 0 while dup to_break::slice::size < {
            as [match i]
            i to_break::slice Arr.get as [brk_kind]
            brk_kind tok::kind TokenKind.equals match lor
            i 1 +
        } drop as [break]

        break lnot if {

            "  Parsing Token: " puts tok Token.puts "\n" puts

            tok Token.keyword Opt.is_some if {
                tok Token.keyword Opt.unwrap as [kw]

                kw Keyword::Cast == if {
                    tok tokens types parse_cast ops Stack.push
                } else kw Keyword::SizeOf == if {
                    tok tokens types parse_size_of ops Stack.push
                } else kw Keyword::While == if {
                    tok tokens ops types parse_while_block
                } else kw Keyword::As == if {
                    tok tokens ops types parse_as
                } else {
                    "  Parsing " puts kw Keyword.puts " isn't implemented yet" putlns
                    1 exit
                }

                
            } else tok Token.word Opt.is_some if {
                
                Stack.new::<Str> as [inner]

                tok Token.word Opt.unwrap as [word]

                tok while tokens Marker::DoubleColon TokenKind.from_marker peek_token_kind  {
                    as [tmp_tok]
                    tmp_tok tokens Marker::DoubleColon TokenKind.from_marker expect_token_kind as [marker_tok]
                    tokens Operator::LessThan TokenKind.from_operator peek_token_kind if {

                        marker_tok tokens types parse_annotation_list as [_ ann]
                        ann annotations !
                        inner Stack.is_empty lnot if {
                            "Cannot have both ann and inner types" putlns
                            1 exit 
                        }
                        marker_tok
                    } else {
                        marker_tok tokens expect_word as [inner_tok field]
                        inner_tok
                        field inner Stack.push
                    }

                } drop
                
                annotations @ Opt.is_some if {
                    "  Parsing annotated function calls isn't implemented yet" putlns
                    1 exit
                } else {
                    
                    tok word inner Op.Ident ops Stack.push

                }

            } else tok Token.operator Opt.is_some if {
                
                tok Op.from_oper_tok ops Stack.push

            } else tok Token.literal Opt.is_some if {
                
                tok Token.literal Opt.unwrap as [lit]
                lit::tag LiteralTag::Str == if {
                    "Parsing string literal isn't implemented yet" putlns
                    1 exit 
                } else {
                    tok Op.from_literal_tok ops Stack.push
                }

            } else {
                "  " puts tok::loc Loc.puts
                ": Parsing " puts
                tok::kind TokenKind.puts
                " isn't implemented yet" putlns
                1 exit
            }

            false tokens Stack.pop

        } else {
            break maybe_tok
        }
    } as [_ tok]

    tok Opt.unwrap

}

fn parse_function(
    Token: start_tok 
    *Stack<Token>: tokens
    *Map<*Type>: types
    // TODO: init data
) -> [*Function] {

    start_tok tokens expect_word as [name_tok name]

    "Parsing function: " puts name putlns

    name_tok tokens types parse_annotation_list as [ann_tok generics]
    ann_tok tokens types parse_signature as [sig_tok sig idents]

    sig::inputs @ as [inputs] {
        0 while dup inputs::len < {
            as [i]

            i inputs::slice Arr.get as [typ_p]
            typ_p @ as [typ] 
            typ::tag TypeKind::Placeholder == if {

                generics Opt.is_some if {
                    generics Opt.unwrap @ as [gen]
                    false 0 while dup gen::len < {
                        as [j]

                        j gen::slice Arr.get cast(u64) typ_p cast(u64) == lor
                        j 1 +
                    } drop

                    lnot if {
                        sig_tok::loc Loc.puts
                        "Unrecognized type: `" puts 
                        typ_p Type.name as [typ_name] // NOTE: typ_name is leaked
                        typ_name puts 
                        "`" putlns
                        "    * Consider adding `" puts typ_name puts "` to the generic list" putlns
                        1 exit
                    }

                } else {
                    name_tok::loc Loc.puts
                    "Unrecognized type `" puts
                    typ_p Type.name as [typ_name] // NOTE: typ_name is leaked
                    "`" putlns
                    "    * Consider adding generics list" putlns
                    1 exit 
                }
            }         

            i 1 +    
        } drop
    }
    
    sig_tok tokens Marker::OpenBrace TokenKind.from_marker expect_token_kind as [body_start_tok]
    Stack.new::<Op> as [ops]

    name_tok Op.PrepareFunc ops Stack.push

    Stack.new::<TokenKind> as [break_on]
    Marker::CloseBrace TokenKind.from_marker break_on Stack.push
    sig_tok tokens ops types break_on parse_tokens_until_tokenkind as [end_tok]
    break_on Stack.destroy

    end_tok Op.Return ops Stack.push

    name start_tok Function.new as [func]
    name start_tok sig ops cast(Function) func !
    func

}

fn parse_type(
    Token: start_tok
    *Stack<Token>: tokens
    *Map<*Type>: types
) -> [Token *Type Opt<u64>] {

    tokens Operator::Mul TokenKind.from_operator peek_token_kind if {

        start_tok tokens Operator::Mul TokenKind.from_operator expect_token_kind as [tok] {
            tok tokens types parse_type 
        } as [tok inner dimension]

        dimension Opt.is_some if {
            start_tok::loc Loc.puts
            ": Pointers cannot have an array dimension" putlns
            1 exit
        }

        inner Type.Pointer as [typ]
        typ Type.name as [name]

        name types Map.contains lnot if {
            typ Type.name typ types Map.insert drop
        }

        tok typ dimension

    } else {

        start_tok tokens expect_word as [name_tok name]
        name_tok tokens types parse_annotation_list as [tok annotations]

        name types Map.get as [maybe_typ]

        maybe_typ Opt.is_some if {

            maybe_typ Opt.unwrap as [typ_p]
            typ_p @ as [typ]
            typ::tag TypeKind::GenericStructBase == if {
                typ_p
                "Parsing Generic Structs isn't implemented yet..." putlns
                1 exit 
            } else typ::tag TypeKind::GenericUnionBase == if {
                typ_p
                "Parsing Generic Unions isn't implemented yet..." putlns
                1 exit 
            } else {
                typ_p
            }

        } else {
            
            name Type.Placeholder as [typ]
            typ Type.name typ types Map.insert drop
            typ

        } as [typ]

        tokens Marker::OpenBracket TokenKind.from_marker peek_token_kind if {

            tok tokens Marker::OpenBracket TokenKind.from_marker expect_token_kind as [open_tok]
            open_tok tokens expect_u64 as [size_tok size]
            size_tok tokens Marker::CloseBracket TokenKind.from_marker expect_token_kind as [close_tok]
            close_tok typ size Opt.Some 

        } else {
            tok typ Opt.None::<u64> 
        }

    }

}

fn parse_untagged_type(
    Token: start_tok
    *Stack<Token>: tokens
    *Map<*Type>: types
) -> [Opt<Token> Opt<*Type> Opt<u64>] {

    tokens Operator::Mul TokenKind.from_operator peek_token_kind
    tokens "" TokenKind.from_word peek_token_kind lor if {
        start_tok tokens types parse_type as [tok name dimension]
        tok Opt.Some name Opt.Some dimension
    } else {
        Opt.None::<Token> Opt.None::<*Type> Opt.None::<u64>
    }
}

fn parse_annotation_list(
    Token: start_tok
    *Stack<Token>: tokens
    *Map<*Type>: types
) -> [Token Opt<*Stack<*Type>>] {

    tokens Operator::LessThan TokenKind.from_operator peek_token_kind if {
        start_tok tokens Operator::LessThan TokenKind.from_operator expect_token_kind as [open_tok]
        Stack.new::<*Type> as [annotations]
        
        open_tok while tokens types parse_untagged_type
            as [maybe_tok maybe_typ dimension] { maybe_tok maybe_typ dimension
            maybe_tok Opt.is_some
            maybe_typ Opt.is_some land
        }
        {
            as [maybe_tok maybe_typ dimension]
            maybe_tok Opt.unwrap maybe_typ Opt.unwrap as [tok typ]
            dimension Opt.is_some if {
                tok::loc Loc.puts
                ": Cannot hav earray values in annotatoins list." putlns
                1 exit
            }

            typ annotations Stack.push
            tok
        } drop drop drop

        start_tok tokens Operator::GreaterThan TokenKind.from_operator expect_token_kind as [close_tok]
        annotations Stack.is_empty if {
            close_tok::loc Loc.puts
            ": Type annotations cannot be empty" putlns
            "    * Consider removing the annotation list." putlns
            1 exit
        }
        
        close_tok annotations Opt.Some

    } else {
        start_tok Opt.None::<*Stack<*Type>>
    }

}

fn hay_into_ir(Str: path *Program: program_p *Stack<Str>: included_files) {

    program_p @ as [program]
    path File.str_from_path as [file_str]
    Stack.new::<Token> as [tokens]

    path file_str tokens parse_tokens tokens Stack.rev
    
    while tokens Stack.pop Opt.unwrap as [token] { token
        token::kind::tag TokenKindTag::EndOfFile == lnot
    }
    {
        as [token]
        token Token.puts "\n" puts
        token Token.keyword Opt.is_some if {
            
            token Token.keyword Opt.unwrap as [kw]

            kw Keyword::Function == if {
                token tokens program::types parse_function program::functions Stack.push
            } else {
                "Lexing keyword `" puts kw Keyword.puts "` isn't implemented yet" putlns
                1 exit  
            }

        } else {
            "Lexing TokenKind `" puts token::kind TokenKind.puts "` isn't implemented yet." putlns
            1 exit 
        }

    } drop
    
    "converting .hay files into intermediate representation isn't finished yet..." putlns
    1 exit 
}